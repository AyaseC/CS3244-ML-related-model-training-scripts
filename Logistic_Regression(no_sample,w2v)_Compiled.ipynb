{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Logistic_Regression(no_sample,w2v)_Compiled.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPQ3pLHlX63FaMPoW5zlfli"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"98KOQ5hV_bWj","executionInfo":{"elapsed":22318,"status":"ok","timestamp":1636975034302,"user":{"displayName":"XIN BIN ONG","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11533603766913951839"},"user_tz":-480},"outputId":"9cb85e19-2b07-4966-8fec-9a57f3e5a20a"},"source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import KFold\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, log_loss, confusion_matrix, classification_report, roc_curve, auc\n","import gensim\n","from gensim.models import word2vec, KeyedVectors\n","from gensim.test.utils import common_texts\n","from google.colab import drive\n","from sklearn.preprocessing import LabelEncoder\n","import pickle\n","drive.mount('/drive')"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /drive\n"]}]},{"cell_type":"code","metadata":{"id":"qbfNh1ve_mRL","executionInfo":{"status":"ok","timestamp":1636978899484,"user_tz":-480,"elapsed":16737,"user":{"displayName":"XIN BIN ONG","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11533603766913951839"}}},"source":["data_type = 'Long' # All, Short, Med,Long\n","if data_type == 'All':\n","  df_reviews = pd.read_json('/drive/MyDrive/Colab Notebooks/CS3244 Machine Learning/CS3244 Group Project/Original_data/IMDB_Review_w_Clean.json')\n","  df_kfold = pd.read_json('/drive/MyDrive/Colab Notebooks/CS3244 Machine Learning/CS3244 Group Project/Original_data/StratifiedKfold_index.json')\n","else:\n","  df_reviews = pd.read_json('/drive/MyDrive/Colab Notebooks/CS3244 Machine Learning/CS3244 Group Project/Original_data/'+data_type.lower()+'_clean_data.json')\n","  df_kfold = pd.read_json('/drive/MyDrive/Colab Notebooks/CS3244 Machine Learning/CS3244 Group Project/Original_data/StratifiedKfold('+data_type.lower()+')_index.json')\n"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"3RXR20BjAJTv"},"source":["# load word2vec model\n","w2vmodel = KeyedVectors.load_word2vec_format(\"/drive/MyDrive/Colab Notebooks/CS3244 Machine Learning/CS3244 Group Project/Word Embedding/w2v_model/w2v_sg1_window5_100d.txt\")\n","model = w2vmodel\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"55_6ii30AR8u"},"source":["def text_vector(texts):\n","    \"\"\"Create document vectors by averaging word vectors. Remove out-of-vocabulary words.\"\"\"\n","    if len(texts) == 0:\n","      print(\"empty text\")\n","    filtered_texts = [word for word in texts if word in model.wv.vocab]\n","    if len(filtered_texts) == 0:\n","      print(\"empty filtered_text\")\n","      print(texts)\n","      print(filtered_texts)\n","      return np.zeros((100,), dtype=float)\n","    else:\n","      return np.mean(w2vmodel[filtered_texts], axis=0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lwToDBsnXcrd","executionInfo":{"status":"ok","timestamp":1636979844854,"user_tz":-480,"elapsed":708304,"user":{"displayName":"XIN BIN ONG","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11533603766913951839"}},"outputId":"4f9e2874-7d8e-4673-892d-3b95130c789a"},"source":["for i in range(0,5):\n","  index_of_kfold = i # 0-4\n","  X_train, X_test = df_reviews[['clean_review_text']].iloc[df_kfold[\"train_index\"][index_of_kfold]], df_reviews[['clean_review_text']].iloc[df_kfold[\"test_index\"][index_of_kfold]]\n","  y_train, y_test = df_reviews[\"is_spoiler\"].iloc[df_kfold[\"train_index\"][index_of_kfold]], df_reviews[\"is_spoiler\"].iloc[df_kfold[\"test_index\"][index_of_kfold]]\n","\n","  lb = LabelEncoder()\n","  y_train_encoded = lb.fit_transform(y_train)\n","  y_test_encoded = lb.fit_transform(y_test)\n","\n","  X_train['text_vector'] = X_train.clean_review_text.apply(text_vector)\n","  X_test['text_vector'] = X_test.clean_review_text.apply(text_vector)\n","\n","  # lb = LabelEncoder()\n","  # y_train_encoded = lb.fit_transform(y_train)\n","\n","  X_train_vector = list(X_train['text_vector'])\n","  X_test_vector = list(X_test['text_vector'])\n","  clfmodel = LogisticRegression(C=100)\n","  clfmodel.fit(X_train_vector, y_train_encoded)\n","  # clfmodel.fit(X_train_vector, y_train_encoded)\n","\n","  y_train_pred = clfmodel.predict(X_train_vector)\n","  y_test_pred = clfmodel.predict(X_test_vector)\n","  print(\"====================Train=============================\")\n","  mnb_score = accuracy_score(y_train_encoded, y_train_pred)\n","  auc_score = roc_auc_score(y_train_encoded,y_train_pred)\n","  print(mnb_score, auc_score)\n","  print(classification_report(y_train_encoded, y_train_pred))\n","  print(confusion_matrix(y_train_encoded, y_train_pred))\n","  print(\"====================Test=============================\")\n","  mnb_score = accuracy_score(y_test_encoded, y_test_pred)\n","  auc_score = roc_auc_score(y_test_encoded,y_test_pred)\n","  print(mnb_score, auc_score)\n","  print(classification_report(y_test_encoded, y_test_pred))\n","  print(confusion_matrix(y_test_encoded, y_test_pred))\n","\n","\n","  df_evaluation  = pd.DataFrame(index=X_test.index)\n","  df_evaluation['LogReg(no_sample,w2v)'] = y_test_pred\n","  df_evaluation.to_csv(\"/drive/MyDrive/Colab Notebooks/CS3244 Machine Learning/CS3244 Group Project/Test_data/\"+data_type+\"_Data/Sample\"+str(index_of_kfold)+\"/logreg(no_sample,w2v).csv\")\n","\n","  \n","  filename = '/drive/MyDrive/Colab Notebooks/CS3244 Machine Learning/CS3244 Group Project/Finished_model/'+data_type+'_Data/Sample'+str(index_of_kfold)+'/logreg(no_sample,w2v)_sample'+str(index_of_kfold)+'.sav'\n","  pickle.dump(clfmodel, open(filename, 'wb'))\n","\n","  # load the model from disk\n","  loaded_model = pickle.load(open(filename, 'rb'))\n","  result = loaded_model.score(X_test_vector, y_test_encoded)\n","  print(result)"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n","  \"\"\"\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"]},{"output_type":"stream","name":"stdout","text":["====================Train=============================\n","0.6718850769483681 0.6485279568905273\n","              precision    recall  f1-score   support\n","\n","           0       0.68      0.80      0.74     45497\n","           1       0.65      0.49      0.56     33582\n","\n","    accuracy                           0.67     79079\n","   macro avg       0.67      0.65      0.65     79079\n","weighted avg       0.67      0.67      0.66     79079\n","\n","[[36559  8938]\n"," [17009 16573]]\n","====================Test=============================\n","0.6580677794638341 0.6300307602077672\n","              precision    recall  f1-score   support\n","\n","           0       0.67      0.82      0.73     11374\n","           1       0.64      0.44      0.52      8396\n","\n","    accuracy                           0.66     19770\n","   macro avg       0.65      0.63      0.63     19770\n","weighted avg       0.65      0.66      0.64     19770\n","\n","[[9283 2091]\n"," [4669 3727]]\n","0.6580677794638341\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n","  \"\"\"\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"]},{"output_type":"stream","name":"stdout","text":["====================Train=============================\n","0.6671050468518823 0.642533417739948\n","              precision    recall  f1-score   support\n","\n","           0       0.68      0.81      0.74     45497\n","           1       0.65      0.48      0.55     33582\n","\n","    accuracy                           0.67     79079\n","   macro avg       0.66      0.64      0.64     79079\n","weighted avg       0.66      0.67      0.66     79079\n","\n","[[36653  8844]\n"," [17481 16101]]\n","====================Test=============================\n","0.6800202326757714 0.6513234613215215\n","              precision    recall  f1-score   support\n","\n","           0       0.68      0.84      0.75     11374\n","           1       0.68      0.46      0.55      8396\n","\n","    accuracy                           0.68     19770\n","   macro avg       0.68      0.65      0.65     19770\n","weighted avg       0.68      0.68      0.67     19770\n","\n","[[9575 1799]\n"," [4527 3869]]\n","0.6800202326757714\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n","  \"\"\"\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"]},{"output_type":"stream","name":"stdout","text":["====================Train=============================\n","0.6658531342075645 0.6414181395657986\n","              precision    recall  f1-score   support\n","\n","           0       0.68      0.80      0.73     45497\n","           1       0.64      0.48      0.55     33582\n","\n","    accuracy                           0.67     79079\n","   macro avg       0.66      0.64      0.64     79079\n","weighted avg       0.66      0.67      0.66     79079\n","\n","[[36561  8936]\n"," [17488 16094]]\n","====================Test=============================\n","0.6790591805766313 0.6548384633576256\n","              precision    recall  f1-score   support\n","\n","           0       0.69      0.82      0.75     11374\n","           1       0.66      0.49      0.57      8396\n","\n","    accuracy                           0.68     19770\n","   macro avg       0.68      0.65      0.66     19770\n","weighted avg       0.68      0.68      0.67     19770\n","\n","[[9277 2097]\n"," [4248 4148]]\n","0.6790591805766313\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n","  \"\"\"\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"]},{"output_type":"stream","name":"stdout","text":["====================Train=============================\n","0.670430834987797 0.6462636763120053\n","              precision    recall  f1-score   support\n","\n","           0       0.68      0.81      0.74     45496\n","           1       0.65      0.49      0.56     33583\n","\n","    accuracy                           0.67     79079\n","   macro avg       0.66      0.65      0.65     79079\n","weighted avg       0.67      0.67      0.66     79079\n","\n","[[36701  8795]\n"," [17267 16316]]\n","====================Test=============================\n","0.6643904906423874 0.6436919149938805\n","              precision    recall  f1-score   support\n","\n","           0       0.68      0.78      0.73     11375\n","           1       0.63      0.51      0.56      8395\n","\n","    accuracy                           0.66     19770\n","   macro avg       0.66      0.64      0.64     19770\n","weighted avg       0.66      0.66      0.66     19770\n","\n","[[8884 2491]\n"," [4144 4251]]\n","0.6643904906423874\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n","  \"\"\"\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"]},{"output_type":"stream","name":"stdout","text":["====================Train=============================\n","0.6742539200809307 0.6510272382993563\n","              precision    recall  f1-score   support\n","\n","           0       0.68      0.81      0.74     45497\n","           1       0.65      0.50      0.56     33583\n","\n","    accuracy                           0.67     79080\n","   macro avg       0.67      0.65      0.65     79080\n","weighted avg       0.67      0.67      0.67     79080\n","\n","[[36634  8863]\n"," [16897 16686]]\n","====================Test=============================\n","0.6507157671101219 0.6308771517707596\n","              precision    recall  f1-score   support\n","\n","           0       0.67      0.76      0.72     11374\n","           1       0.61      0.50      0.55      8395\n","\n","    accuracy                           0.65     19769\n","   macro avg       0.64      0.63      0.63     19769\n","weighted avg       0.65      0.65      0.64     19769\n","\n","[[8673 2701]\n"," [4204 4191]]\n","0.6507157671101219\n"]}]}]}